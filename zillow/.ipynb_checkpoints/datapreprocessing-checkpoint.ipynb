{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "transaction=pd.read_csv('../input/train_2016.csv', parse_dates=[\"transactiondate\"]);\n",
    "transaction['sale_month']=transaction['transactiondate'].apply(lambda x: (x.to_datetime()).month)\n",
    "transaction['sale_day']=transaction['transactiondate'].apply(lambda x: (x.to_datetime()).day)\n",
    "transaction['sale_year']=transaction['transactiondate'].apply(lambda x: (x.to_datetime()).year)\n",
    "transaction['sale_month'].astype(int,inplace=True)\n",
    "transaction.drop(['transactiondate','sale_day','sale_year'],axis=1,inplace=True)\n",
    "properties_2016=pd.read_csv('../input/properties_2016.csv',low_memory=False);\n",
    "# data type analysis\n",
    "dtype_df = properties_2016.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Feature\", \"Column Type\"]\n",
    "dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()\n",
    "properties_2016.drop(dtype_df[dtype_df['Column Type']=='object']['Feature'].values.tolist(),axis=1,inplace=True)\n",
    "# check the missing percentage\n",
    "missing_df = properties_2016.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "missing_df['missing_rate']=missing_df['missing_count']/2985217\n",
    "cutoff=0.9\n",
    "# drop feature missing rate>0.9\n",
    "properties_2016.drop(missing_df[(missing_df.missing_rate>=cutoff)].column_name.values.tolist(),\n",
    "                    axis=1,inplace=True)\n",
    "# categorize the left feature\n",
    "id_feature_left=['propertylandusetypeid','assessmentyear','yearbuilt',\n",
    "                'buildingqualitytypeid','heatingorsystemtypeid','fips','rawcensustractandblock',\n",
    "                'regionidzip','regionidcity']\n",
    "cnt_feature_left=['bedroomcnt','bathroomcnt','roomcnt','calculatedbathnbr','fullbathcnt',\n",
    "                 'unitcnt','garagecarcnt','airconditioningtypeid','numberofstories',\n",
    "                  'poolcnt','pooltypeid7','fireplacecnt','threequarterbathnbr']\n",
    "size_feature_left=['taxamount','taxvaluedollarcnt','structuretaxvaluedollarcnt',\n",
    "                   'calculatedfinishedsquarefeet','landtaxvaluedollarcnt','finishedsquarefeet12',\n",
    "                  'lotsizesquarefeet','longitude','latitude','garagetotalsqft']\n",
    "location_feature_left=['regionidcounty','censustractandblock','regionidneighborhood']\n",
    "# fill missing values\n",
    "# for id_feature, fill the missing values with most frequent value\n",
    "# for cnt_feature, fill the missing values with median value\n",
    "# for size_feature, fill the missing values with mean values\n",
    "# for location_feature, fill the missing values with the nearest values\n",
    "fill_missing_value=dict()\n",
    "# for id_feature\n",
    "for x in id_feature_left:\n",
    "    fill_missing_value[x]=properties_2016[x].value_counts().index.tolist()[0]\n",
    "# for cnt_feature\n",
    "for x in cnt_feature_left:\n",
    "    fill_missing_value[x]=properties_2016[x].median()\n",
    "# for size_feature\n",
    "for x in size_feature_left:\n",
    "    fill_missing_value[x]=properties_2016[x].mean()\n",
    "for x in fill_missing_value:\n",
    "    properties_2016[x].fillna(fill_missing_value[x],inplace=True)\n",
    "# for location_feature\n",
    "# regionidcounty and fips is the same to represent the county keep fips\n",
    "# censustractandblock is drop as to be the same as rawcensustractandblock.\n",
    "# regionidneighborhood >60% missing rate is droped\n",
    "properties_2016.drop(['regionidcounty','regionidneighborhood','censustractandblock'],axis=1,inplace=True)\n",
    "# the maximum missing rate for the left location feature is 2% maximum. drop the rows with\n",
    "# missing values\n",
    "#properties_2016.dropna(axis=0,how='any',inplace=True)\n",
    "#properties_2016.fillna(0,inplace=True)\n",
    "# divide 1000000 for longitude and latitude\n",
    "properties_2016['longitude']=properties_2016['longitude']/1000000;\n",
    "properties_2016['latitude']=properties_2016['latitude']/1000000;\n",
    "# add new features\n",
    "# 1. tax per living area = tax amount/calculatedfinishedsquarefeet\n",
    "# 2. tax per living area2 =tax amount/finishedsquarefeet12\n",
    "# 3. tax per lot size=taxamount/lotsizesquarefeet\n",
    "properties_2016['tax_per_liv_area']=properties_2016['taxamount']/properties_2016['calculatedfinishedsquarefeet'];\n",
    "properties_2016['tax_per_liv_area2']=properties_2016['taxamount']/properties_2016['finishedsquarefeet12'];\n",
    "properties_2016['tax_per_lot_size']=properties_2016['taxamount']/properties_2016['lotsizesquarefeet'];\n",
    "# achieve data with transaction information\n",
    "train_df=transaction.merge(properties_2016,on='parcelid',how='left')\n",
    "# drop missing value which indicates these properties have no complete location information\n",
    "train_df.dropna(axis=0,how='any',inplace=True)\n",
    "print((len(transaction)-len(train_df))/len(transaction)*100,'% data has been removed due to the missing',\n",
    "     'location information.')\n",
    "# drop transactiondata, sale_year\n",
    "#train_df.drop(['transactiondate','sale_year'],axis=1,inplace=True)\n",
    "# drop sale_day since there is not enough data to resolve resolution in day\n",
    "#train_df.drop('sale_day',axis=1,inplace=True)\n",
    "# set parcel id as index\n",
    "train_df.set_index('parcelid',inplace=True)\n",
    "# drop pooltypeid7\n",
    "properties_2016.drop('pooltypeid7',inplace=True,axis=1)\n",
    "properties_2016.drop('poolcnt',inplace=True,axis=1)\n",
    "#  7+12+3+14+15\n",
    "dummy_feature=['airconditioningtypeid','buildingqualitytypeid','fips','heatingorsystemtypeid',\n",
    "              'propertylandusetypeid']\n",
    "\n",
    "# normalize all features except dummy feature\n",
    "features=properties_2016.columns.tolist()\n",
    "for x in list(set(features)-set(dummy_feature)-set(['pooltypeid7','poolcnt','parcelid'])):\n",
    "    feature_max=properties_2016[x].max()\n",
    "    feature_min=properties_2016[x].min()\n",
    "    if(feature_max==feature_min):\n",
    "        print(x,'max==min, cannot normalize, max=',feature_max)\n",
    "    else:\n",
    "        properties_2016[x]=(properties_2016[x]-feature_min)/(feature_max-feature_min)\n",
    "# add dummy variables\n",
    "for x in dummy_feature:\n",
    "    a=pd.get_dummies(properties_2016[x])\n",
    "    print(a.shape)\n",
    "    a.columns=[x+'_'+str(n) for n in a.columns.tolist()]\n",
    "    properties_2016=pd.concat([properties_2016,a], axis=1)\n",
    "print(\"new properties shape:\",properties_2016.shape)\n",
    "# drop dummy feature\n",
    "properties_2016.drop(dummy_feature,axis=1,inplace=True)\n",
    "train_df=transaction.merge(properties_2016,on='parcelid',how='left')\n",
    "#train_df.drop(['transactiondate','sale_year'],axis=1,inplace=True)\n",
    "# drop sale_day since there is not enough data to resolve resolution in day\n",
    "#train_df.drop('sale_day',axis=1,inplace=True)\n",
    "# set parcel id as index\n",
    "train_df.set_index('parcelid',inplace=True)\n",
    "train_df['sale_month']=train_df['sale_month']/12;\n",
    "# add one column as the absolute value of log error\n",
    "#train_df['abs_logerror']=train_df['logerror'].abs()\n",
    "# get X_train y_train\n",
    "X_train=train_df.iloc[:,1:]\n",
    "#X_train.set_index('parcelid',inplace=True)\n",
    "y_train=train_df['logerror']\n",
    "# generate X_test\n",
    "# load sample submission for output\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(properties_2016, on='parcelid', how='left')\n",
    "# still need the sale month as input\n",
    "train_feature=properties_2016.columns.tolist()\n",
    "X_test=df_test[train_feature]\n",
    "X_test.set_index('parcelid',inplace=True)\n",
    "# predict with linear regress\n",
    "X_test['sale_month']=10/12\n",
    "X_test=X_test[X_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "split = 90000\n",
    "x_train, y_train, x_valid, y_valid = X_train[:split], y_train[:split], X_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n",
    "\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.002\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 60\n",
    "params['min_data'] = 500\n",
    "params['min_hessian'] = 1\n",
    "\n",
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 500, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=pd.read_csv('../input/sample_submission.csv')\n",
    "output.set_index('ParcelId',inplace=True)\n",
    "clf.reset_parameter({\"num_threads\":1})\n",
    "for mon in [10,11,12]:\n",
    "    X_test['sale_month']=mon/12;\n",
    "    p_test = clf.predict(X_test)\n",
    "    output['2016'+str(mon)]=p_test\n",
    "output.to_csv('lgb0605.csv', float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
